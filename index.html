<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Note App</title>
    <!-- Tailwind CSS CDN for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styles for a cleaner look */
        body {
            font-family: 'Inter', sans-serif;
            display: flex;
            flex-direction: column; /* Changed to column to allow footer at bottom */
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            padding: 20px;
            /* Dark Mode Theme Background */
            background-color: #1a202c; /* Dark charcoal */
            background-image: url('https://placehold.co/1920x1080/1A202C/6B7280?text=Abstract+Dark+Background'); /* Placeholder - Replace with a dark, abstract image */
            background-size: cover;
            background-position: center;
            background-attachment: fixed;
            position: relative;
            z-index: 0;
        }

        /* Overlay for subtle transparency effect */
        body::before {
            content: "";
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.6); /* Dark overlay with 60% opacity */
            z-index: -1;
        }

        .container {
            background-color: rgba(30, 41, 59, 0.9); /* Dark blue-gray, slightly transparent */
            border-radius: 16px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.4); /* Stronger shadow for dark mode */
            padding: 30px;
            width: 100%;
            max-width: 600px;
            z-index: 1;
            position: relative;
            border: 1px solid rgba(71, 85, 105, 0.5); /* Subtle border */
            margin-bottom: 20px; /* Space for the footer */
        }
        
        /* Button animations */
        .button-group button {
            transition: background-color 0.3s ease-in-out, transform 0.2s ease-out, box-shadow 0.3s ease-in-out;
            border: none; /* Remove default button borders */
        }
        .button-group button:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);
        }
        .button-group button:active {
            transform: translateY(0);
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
        }

        /* Recording indicator animation */
        .recording-indicator {
            animation: pulse 1.5s infinite cubic-bezier(0.4, 0, 0.6, 1);
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.05); opacity: 0.7; }
            100% { transform: scale(1); opacity: 1; }
        }

        /* Loading spinner animation */
        .spinner {
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-top: 4px solid #3b82f6; /* Blue */
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        /* Status message animation */
        .status-fade-in {
            animation: fadeIn 0.5s ease-out forwards;
        }
        .status-fade-out {
            animation: fadeOut 0.5s ease-in forwards;
        }
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        @keyframes fadeOut {
            from { opacity: 1; transform: translateY(0); }
            to { opacity: 0; transform: translateY(-10px); }
        }
    </style>
</head>
<body>
    <div class="container flex flex-col items-center space-y-6">
        <h1 class="text-3xl font-bold text-gray-100 mb-4">Voice Note App</h1>

        <!-- Status Message Area -->
        <div id="statusMessage" class="text-center text-sm font-medium text-gray-300 min-h-[20px] status-fade-in">
            Ready to record.
        </div>

        <!-- Recording Controls -->
        <div class="button-group flex flex-wrap justify-center gap-4 w-full">
            <button id="startRecord"
                    class="bg-blue-600 text-white px-6 py-3 rounded-xl shadow-lg hover:bg-blue-700 focus:outline-none focus:ring-4 focus:ring-blue-500/50 flex items-center justify-center">
                <svg class="w-6 h-6 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7v1m0 0v1m0-1a7 7 0 01-7-7m7 7v-1m0 0V5a2 2 0 012-2h4a2 2 0 012 2v6a2 2 0 01-2 2h-4a2 2 0 01-2-2z"></path></svg>
                Start Recording
            </button>

            <button id="stopAndTranscribe" disabled
                    class="bg-red-600 text-white px-6 py-3 rounded-xl shadow-lg opacity-50 cursor-not-allowed hover:bg-red-700 focus:outline-none focus:ring-4 focus:ring-red-500/50 flex items-center justify-content-center">
                <svg class="w-6 h-6 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 12a9 9 0 11-18 0 9 9 0 0118 0zM9 10H7v4h2v-4zm8 0h-2v4h2v-4z"></path></svg>
                Stop & Transcribe
            </button>
        </div>

        <!-- Audio element (kept hidden for internal mediaRecorder use) -->
        <audio id="audioPlayer" class="w-full mt-4 hidden" controls></audio>

        <!-- Transcript Display and Edit Area -->
        <div class="w-full bg-gray-800 p-4 rounded-xl border border-gray-700 mt-6">
            <h2 class="text-xl font-semibold text-gray-100 mb-3">Transcript:</h2>
            <textarea id="transcriptOutput"
                      class="w-full p-3 border border-gray-600 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-400 resize-y text-gray-100 bg-gray-900 text-base leading-relaxed min-h-[120px]"
                      rows="6"
                      placeholder="Your transcribed or manually entered text will appear here. You can edit it directly."
            ></textarea>
        </div>

        <!-- Action Buttons for Transcript -->
        <div class="flex flex-wrap justify-center gap-4 w-full mt-4">
            <button id="copyTextBtn" disabled
                    class="bg-gray-700 text-white px-6 py-3 rounded-xl shadow-lg opacity-50 cursor-not-allowed hover:bg-gray-800 focus:outline-none focus:ring-4 focus:ring-gray-500/50 flex items-center justify-center">
                <svg class="w-6 h-6 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4a2 2 0 012 2v4m-5 4l-4-4"></path></svg>
                Copy All Text
            </button>

            <button id="saveToNotionBtn" disabled
                    class="bg-indigo-600 text-white px-6 py-3 rounded-xl shadow-lg opacity-50 cursor-not-allowed hover:bg-indigo-700 focus:outline-none focus:ring-4 focus:ring-indigo-500/50 flex items-center justify-center">
                <svg class="w-6 h-6 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg>
                Save to Notion
            </button>

            <!-- New LLM-powered feature buttons -->
            <button id="summarizeBtn" disabled
                    class="bg-green-600 text-white px-6 py-3 rounded-xl shadow-lg opacity-50 cursor-not-allowed hover:bg-green-700 focus:outline-none focus:ring-4 focus:ring-green-500/50 flex items-center justify-center">
                ✨ Summarize Note
            </button>
            <button id="keywordsBtn" disabled
                    class="bg-yellow-600 text-white px-6 py-3 rounded-xl shadow-lg opacity-50 cursor-not-allowed hover:bg-yellow-700 focus:outline-none focus:ring-4 focus:ring-yellow-500/50 flex items-center justify-center">
                ✨ Extract Keywords
            </button>
            <button id="translateBtn" disabled
                    class="bg-purple-600 text-white px-6 py-3 rounded-xl shadow-lg opacity-50 cursor-not-allowed hover:bg-purple-700 focus:outline-none focus:ring-4 focus:ring-purple-500/50 flex items-center justify-center">
                ✨ Translate to English
            </button>
        </div>

    </div>

    <!-- Footer -->
    <footer class="mt-8 text-center text-gray-400 text-sm">
        Created by AZM
    </footer>

    <script>
        // DOM Elements
        const startRecordBtn = document.getElementById('startRecord');
        const stopAndTranscribeBtn = document.getElementById('stopAndTranscribe');
        const audioPlayer = document.getElementById('audioPlayer'); 
        const transcriptOutput = document.getElementById('transcriptOutput');
        const statusMessage = document.getElementById('statusMessage');
        const copyTextBtn = document.getElementById('copyTextBtn');
        const saveToNotionBtn = document.getElementById('saveToNotionBtn');
        const summarizeBtn = document.getElementById('summarizeBtn'); // New
        const keywordsBtn = document.getElementById('keywordsBtn');   // New
        const translateBtn = document.getElementById('translateBtn'); // New

        // MediaRecorder variables
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob = null;
        let audioUrl = null; 

        // Function to update button states and messages
        function updateUI(state, message = '') {
            // Reset all buttons to disabled and opaque by default
            startRecordBtn.disabled = true;
            stopAndTranscribeBtn.disabled = true;
            copyTextBtn.disabled = true;
            saveToNotionBtn.disabled = true;
            summarizeBtn.disabled = true; // New
            keywordsBtn.disabled = true;   // New
            translateBtn.disabled = true; // New

            startRecordBtn.classList.add('opacity-50', 'cursor-not-allowed');
            stopAndTranscribeBtn.classList.add('opacity-50', 'cursor-not-allowed');
            copyTextBtn.classList.add('opacity-50', 'cursor-not-allowed');
            saveToNotionBtn.classList.add('opacity-50', 'cursor-not-allowed');
            summarizeBtn.classList.add('opacity-50', 'cursor-not-allowed'); // New
            keywordsBtn.classList.add('opacity-50', 'cursor-not-allowed');   // New
            translateBtn.classList.add('opacity-50', 'cursor-not-allowed'); // New

            startRecordBtn.classList.remove('recording-indicator'); // Remove pulse animation

            audioPlayer.src = ''; // Clear previous audio src
            if (audioUrl) {
                URL.revokeObjectURL(audioUrl); // Clean up previous object URL
                audioUrl = null;
            }

            // Apply fade-out before changing message, then fade-in
            statusMessage.classList.remove('status-fade-in');
            statusMessage.classList.add('status-fade-out');
            setTimeout(() => {
                statusMessage.textContent = message;
                statusMessage.classList.remove('status-fade-out');
                statusMessage.classList.add('status-fade-in');
            }, 300); // Match fade-out duration

            switch (state) {
                case 'ready':
                    startRecordBtn.disabled = false;
                    startRecordBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    statusMessage.textContent = 'Ready to record or type your note.';
                    transcriptOutput.value = ''; // Clear transcript on ready
                    audioBlob = null;
                    audioChunks = [];
                    // If there's already text in transcriptOutput (e.g., after manual edit), allow copy/save
                    if (transcriptOutput.value.trim() !== '') {
                        copyTextBtn.disabled = false;
                        saveToNotionBtn.disabled = false;
                        copyTextBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                        saveToNotionBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                        // Also enable LLM buttons if text is present
                        summarizeBtn.disabled = false;
                        keywordsBtn.disabled = false;
                        translateBtn.disabled = false;
                        summarizeBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                        keywordsBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                        translateBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    }
                    break;
                case 'recording':
                    stopAndTranscribeBtn.disabled = false;
                    stopAndTranscribeBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    startRecordBtn.classList.add('recording-indicator');
                    statusMessage.textContent = 'Recording... Say something!';
                    break;
                case 'transcribing':
                    statusMessage.textContent = 'Transcribing audio... Please wait.';
                    transcriptOutput.value = 'Transcribing...'; // Show immediate feedback
                    break;
                case 'processing_llm': // New state for LLM operations
                    statusMessage.textContent = `Processing with Gemini... Please wait.`;
                    // All buttons remain disabled during LLM processing
                    break;
                case 'transcribed_for_review':
                    startRecordBtn.disabled = false;
                    copyTextBtn.disabled = false;
                    saveToNotionBtn.disabled = false;
                    summarizeBtn.disabled = false; // New
                    keywordsBtn.disabled = false;   // New
                    translateBtn.disabled = false; // New

                    startRecordBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    copyTextBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    saveToNotionBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    summarizeBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    keywordsBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    translateBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    statusMessage.textContent = 'Transcript ready for review. Edit, copy, or save.';
                    break;
                case 'saving_to_notion':
                    statusMessage.textContent = 'Saving text to Notion...';
                    break;
                case 'saved':
                    statusMessage.textContent = 'Successfully saved to Notion!';
                    transcriptOutput.value = ''; // Clear transcript after successful save
                    updateUI('ready'); // Go back to ready state
                    break;
                case 'error':
                    // Error message set by caller, just update UI state for buttons
                    startRecordBtn.disabled = false;
                    startRecordBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    if (transcriptOutput.value.trim() !== '' && transcriptOutput.value.trim() !== 'Transcribing...') {
                        copyTextBtn.disabled = false;
                        saveToNotionBtn.disabled = false;
                        summarizeBtn.disabled = false; // New
                        keywordsBtn.disabled = false;   // New
                        translateBtn.disabled = false; // New

                        copyTextBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                        saveToNotionBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                        summarizeBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                        keywordsBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                        translateBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    }
                    break;
            }
        }

        // Function to handle transcription logic
        async function handleTranscription() {
            if (!audioBlob || audioBlob.size === 0) {
                statusMessage.textContent = 'No audio recorded to transcribe.';
                updateUI('error');
                return;
            }

            updateUI('transcribing');

            const reader = new FileReader();
            reader.readAsDataURL(audioBlob);
            reader.onloadend = async () => {
                const base64Audio = reader.result.split(',')[1];

                try {
                    const response = await fetch('/api/transcribe-and-save', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            audio: base64Audio,
                            mimeType: audioBlob.type,
                        }),
                    });

                    const data = await response.json();

                    if (response.ok) {
                        const transcribedText = data.transcript || 'No transcript returned.';
                        transcriptOutput.value = transcribedText;
                        updateUI('transcribed_for_review');
                    } else {
                        throw new Error(data.error || 'Unknown error from API.');
                    }
                } catch (error) {
                    console.error('Error sending audio to API for transcription:', error);
                    transcriptOutput.value = `Error: ${error.message}`;
                    updateUI('error');
                }
            };
            reader.onerror = (error) => {
                console.error('Error reading audio Blob:', error);
                statusMessage.textContent = 'Error processing audio for transcription.';
                updateUI('error');
            };
        }

        // New function to process text with Gemini for summary, keywords, or translation
        async function processTextWithGemini(action) {
            const textToProcess = transcriptOutput.value.trim();

            if (!textToProcess) {
                statusMessage.textContent = `Please enter or transcribe some text to ${action}.`;
                return;
            }

            updateUI('processing_llm'); // Set new processing state

            try {
                const response = await fetch('/api/process-transcript', { // New API endpoint
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        text: textToProcess,
                        action: action,
                    }),
                });

                const data = await response.json();

                if (response.ok) {
                    transcriptOutput.value = data.result || `No ${action} returned.`;
                    updateUI('transcribed_for_review'); // Go back to review state after processing
                    statusMessage.textContent = `${action.charAt(0).toUpperCase() + action.slice(1)} complete!`;
                } else {
                    throw new Error(data.error || 'Unknown error from API.');
                }
            } catch (error) {
                console.error(`Error processing text for ${action}:`, error);
                transcriptOutput.value = `Error performing ${action}: ${error.message}`;
                updateUI('error');
            }
        }


        // Initialize UI on load
        document.addEventListener('DOMContentLoaded', () => {
            updateUI('ready');
            // Listen for manual input changes in the textarea
            transcriptOutput.addEventListener('input', () => {
                if (transcriptOutput.value.trim() !== '') {
                    copyTextBtn.disabled = false;
                    saveToNotionBtn.disabled = false;
                    summarizeBtn.disabled = false; // Enable LLM buttons
                    keywordsBtn.disabled = false;
                    translateBtn.disabled = false;

                    copyTextBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    saveToNotionBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    summarizeBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    keywordsBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    translateBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                } else {
                    copyTextBtn.disabled = true;
                    saveToNotionBtn.disabled = true;
                    summarizeBtn.disabled = true; // Disable LLM buttons
                    keywordsBtn.disabled = true;
                    translateBtn.disabled = true;

                    copyTextBtn.classList.add('opacity-50', 'cursor-not-allowed');
                    saveToNotionBtn.classList.add('opacity-50', 'cursor-not-allowed');
                    summarizeBtn.classList.add('opacity-50', 'cursor-not-allowed');
                    keywordsBtn.classList.add('opacity-50', 'cursor-not-allowed');
                    translateBtn.classList.add('opacity-50', 'cursor-not-allowed');
                }
            });
        });

        // Event listener for starting recording
        startRecordBtn.addEventListener('click', async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = () => {
                    audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    if (audioBlob.size === 0) {
                        console.error('Recorded audio Blob is empty!');
                        statusMessage.textContent = 'Recording failed: No audio captured. Try again.';
                        updateUI('error');
                        stream.getTracks().forEach(track => track.stop());
                        return;
                    }

                    audioUrl = URL.createObjectURL(audioBlob);
                    console.log('Audio Blob created:', audioBlob.type, audioBlob.size, 'bytes. URL:', audioUrl);
                    stream.getTracks().forEach(track => track.stop()); // Stop microphone stream

                    // Directly trigger transcription after stopping recording
                    handleTranscription(); 
                };

                mediaRecorder.start();
                updateUI('recording');

            } catch (err) {
                console.error('Error accessing microphone:', err);
                statusMessage.textContent = 'Error: Could not access microphone. Please allow access.';
                updateUI('error');
            }
        });

        // Event listener for stopping recording (now "Stop & Transcribe")
        stopAndTranscribeBtn.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
        });

        // Event listener for Copy All Text button
        copyTextBtn.addEventListener('click', () => {
            if (transcriptOutput.value.trim() !== '') {
                const originalSelectionStart = transcriptOutput.selectionStart;
                const originalSelectionEnd = transcriptOutput.selectionEnd;

                transcriptOutput.select();
                transcriptOutput.setSelectionRange(0, 99999);

                try {
                    const success = document.execCommand('copy');
                    if (success) {
                        statusMessage.textContent = 'Text copied to clipboard!';
                    } else {
                        statusMessage.textContent = 'Failed to copy text. Please copy manually.';
                        console.error('document.execCommand("copy") returned false.');
                    }
                } catch (err) {
                    console.error('Failed to copy text (exception): ', err);
                    statusMessage.textContent = 'Failed to copy text. Please copy manually.';
                } finally {
                    transcriptOutput.setSelectionRange(originalSelectionStart, originalSelectionEnd);
                    transcriptOutput.focus();
                }
            } else {
                statusMessage.textContent = 'No text to copy.';
            }
        });

        // Event listener for Save to Notion button
        saveToNotionBtn.addEventListener('click', async () => {
            const textToSave = transcriptOutput.value.trim();

            if (!textToSave) {
                statusMessage.textContent = 'Please enter or transcribe some text to save to Notion.';
                return;
            }

            updateUI('saving_to_notion');

            try {
                const response = await fetch('/api/transcribe-and-save', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        transcript: textToSave, // Send the current text from the textarea
                    }),
                });

                const data = await response.json();

                if (response.ok) {
                    // Update the transcriptOutput with the potentially corrected text from API
                    transcriptOutput.value = data.transcript || textToSave; 
                    updateUI('saved');
                } else {
                    throw new Error(data.error || 'Unknown error from API.');
                }
            } catch (error) {
                console.error('Error saving text to Notion:', error);
                transcriptOutput.value = `Error: ${error.message}`;
                updateUI('error');
            }
        });

        // Event listeners for new LLM buttons
        summarizeBtn.addEventListener('click', () => processTextWithGemini('summarize'));
        keywordsBtn.addEventListener('click', () => processTextWithGemini('keywords'));
        translateBtn.addEventListener('click', () => processTextWithGemini('translate'));

    </script>
</body>
</html>
