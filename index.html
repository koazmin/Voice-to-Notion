<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Note App</title>
    <!-- Tailwind CSS CDN for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styles for a cleaner look */
        body {
            font-family: 'Inter', sans-serif;
            display: flex;
            flex-direction: column; /* Changed to column to allow footer at bottom */
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            padding: 20px;
            /* Dark Mode Theme Background */
            background-color: #1a202c; /* Dark charcoal */
            background-image: url('https://placehold.co/1920x1080/1A202C/6B7280?text=Abstract+Dark+Background'); /* Placeholder - Replace with a dark, abstract image */
            background-size: cover;
            background-position: center;
            background-attachment: fixed;
            position: relative;
            z-index: 0;
        }

        /* Overlay for subtle transparency effect */
        body::before {
            content: "";
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.6); /* Dark overlay with 60% opacity */
            z-index: -1;
        }

        .container {
            background-color: rgba(30, 41, 59, 0.9); /* Dark blue-gray, slightly transparent */
            border-radius: 16px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.4); /* Stronger shadow for dark mode */
            padding: 30px;
            width: 100%;
            max-width: 1024px; /* Increased max-width for a wider layout (equivalent to Tailwind's max-w-5xl) */
            z-index: 1;
            position: relative;
            border: 1px solid rgba(71, 85, 105, 0.5); /* Subtle border */
            margin-bottom: 20px; /* Space for the footer */
        }
        
        /* Button animations */
        .button-group button {
            transition: background-color 0.3s ease-in-out, transform 0.2s ease-out, box-shadow 0.3s ease-in-out;
            border: none; /* Remove default button borders */
            min-width: 180px; /* Uniform button size */
        }
        .button-group button:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);
        }
        .button-group button:active {
            transform: translateY(0);
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
        }

        /* Recording indicator animation */
        .recording-indicator {
            animation: pulse 1.5s infinite cubic-bezier(0.4, 0, 0.6, 1);
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.05); opacity: 0.7; }
            100% { transform: scale(1); opacity: 1; }
        }

        /* Loading spinner animation */
        .spinner {
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-top: 4px solid #3b82f6; /* Blue */
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        /* Status message animation */
        .status-fade-in {
            animation: fadeIn 0.5s ease-out forwards;
        }
        .status-fade-out {
            animation: fadeOut 0.5s ease-in forwards;
        }
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        @keyframes fadeOut {
            from { opacity: 1; transform: translateY(0); }
            to { opacity: 0; transform: translateY(-10px); }
        }
    </style>
</head>
<body>
    <div class="container flex flex-col items-center space-y-4">
        <h1 class="text-3xl font-bold text-gray-100 mb-2">Voice Note App</h1>

        <!-- Status Message Area -->
        <div id="statusMessage" class="text-center text-sm font-medium text-gray-300 min-h-[20px] status-fade-in">
            Ready to record.
        </div>

        <!-- Recording Controls -->
        <div class="button-group flex flex-wrap justify-center gap-4 w-full">
            <button id="startRecord"
                    class="bg-blue-600 text-white px-6 py-3 rounded-xl shadow-lg hover:bg-blue-700 focus:outline-none focus:ring-4 focus:ring-blue-500/50 flex items-center justify-center">
                <svg class="w-6 h-6 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7v1m0 0v1m0-1a7 7 0 01-7-7m7 7v-1m0 0V5a2 2 0 012-2h4a2 2 0 012 2v6a2 2 0 01-2 2h-4a2 2 0 01-2-2z"></path></svg>
                Start Recording
            </button>

            <button id="stopAndTranscribe" disabled
                    class="bg-red-600 text-white px-6 py-3 rounded-xl shadow-lg opacity-50 cursor-not-allowed hover:bg-red-700 focus:outline-none focus:ring-4 focus:ring-red-500/50 flex items-center justify-content-center">
                <svg class="w-6 h-6 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 12a9 9 0 11-18 0 9 9 0 0118 0zM9 10H7v4h2v-4zm8 0h-2v4h2v-4z"></path></svg>
                Stop & Transcribe
            </button>
        </div>

        <!-- Audio element (kept hidden for internal mediaRecorder use) -->
        <audio id="audioPlayer" class="w-full mt-4 hidden" controls></audio>

        <!-- Template Selection -->
        <div class="w-full flex flex-col md:flex-row items-center justify-center gap-4 mt-6">
            <label for="templateSelect" class="text-gray-200 text-lg font-semibold">Template:</label>
            <select id="templateSelect" 
                    class="bg-gray-700 text-white p-2 rounded-lg border border-gray-600 focus:outline-none focus:ring-2 focus:ring-blue-400"
                    onchange="applyTemplate()">
                <option value="general">General</option>
                <option value="meeting_notes">Meeting Notes</option>
                <option value="brainstorming">Brainstorming</option>
                <option value="interview">Interview</option>
            </select>
        </div>

        <!-- Transcript Display and Edit Area -->
        <div class="w-full bg-gray-800 p-4 rounded-xl border border-gray-700 mt-6">
            <h2 class="text-xl font-semibold text-gray-100 mb-3">Transcript:</h2>
            <textarea id="transcriptOutput"
                      class="w-full p-3 border border-gray-600 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-400 resize-y text-gray-100 bg-gray-900 text-base leading-relaxed min-h-[120px]"
                      rows="6"
                      placeholder="Your transcribed or manually entered text will appear here. You can edit it directly."
            ></textarea>
        </div>

        <!-- Action Buttons for Transcript -->
        <div class="flex flex-wrap justify-center gap-4 w-full mt-4">
            <button id="copyTextBtn" disabled
                    class="bg-gray-700 text-white px-6 py-3 rounded-xl shadow-lg opacity-50 cursor-not-allowed hover:bg-gray-800 focus:outline-none focus:ring-4 focus:ring-gray-500/50 flex items-center justify-center">
                <svg class="w-6 h-6 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7v8a2 2 0 002 2h6M8 7V5a2 2 0 012-2h4a2 2 0 012 2v4m-5 4l-4-4"></path></svg>
                Copy All Text
            </button>

            <button id="saveToNotionBtn" disabled
                    class="bg-indigo-600 text-white px-6 py-3 rounded-xl shadow-lg opacity-50 cursor-not-allowed hover:bg-indigo-700 focus:outline-none focus:ring-4 focus:ring-indigo-500/50 flex items-center justify-center">
                <svg class="w-6 h-6 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg>
                Save to Notion
            </button>

            <!-- LLM-powered feature buttons -->
            <button id="summarizeBtn" disabled
                    class="bg-green-600 text-white px-6 py-3 rounded-xl shadow-lg opacity-50 cursor-not-allowed hover:bg-green-700 focus:outline-none focus:ring-4 focus:ring-green-500/50 flex items-center justify-center">
                ✨ Summarize Note
            </button>
            <button id="translateBtn" disabled
                    class="bg-purple-600 text-white px-6 py-3 rounded-xl shadow-lg opacity-50 cursor-not-allowed hover:bg-purple-700 focus:outline-none focus:ring-4 focus:ring-purple-500/50 flex items-center justify-center">
                ✨ Translate to English
            </button>
        </div>

        <!-- Ask Gemini Mode -->
        <div class="w-full bg-gray-800 p-4 rounded-xl border border-gray-700 mt-6">
            <h2 class="text-xl font-semibold text-gray-100 mb-3">Ask Gemini (Burmese):</h2>
            <button id="askGeminiBtn" disabled
                    class="bg-blue-500 text-white px-6 py-3 rounded-xl shadow-lg opacity-50 cursor-not-allowed hover:bg-blue-600 focus:outline-none focus:ring-4 focus:ring-blue-400/50 flex items-center justify-center w-full min-w-[180px]">
                Ask Gemini
            </button>
            <div id="geminiAnswerOutput"
                 class="w-full p-3 mt-3 border border-gray-600 rounded-lg bg-gray-900 text-gray-100 text-base min-h-[80px] overflow-auto"
                 style="white-space: pre-wrap;"
            >
                Gemini's answer will appear here.
            </div>
        </div>

    </div>

    <!-- Footer -->
    <footer class="mt-8 text-center text-gray-400 text-sm">
        Created by AZM
    </footer>

    <script>
        // DOM Elements
        const startRecordBtn = document.getElementById('startRecord');
        const stopAndTranscribeBtn = document.getElementById('stopAndTranscribe');
        const audioPlayer = document.getElementById('audioPlayer'); 
        const transcriptOutput = document.getElementById('transcriptOutput');
        const statusMessage = document.getElementById('statusMessage');
        const copyTextBtn = document.getElementById('copyTextBtn');
        const saveToNotionBtn = document.getElementById('saveToNotionBtn');
        const summarizeBtn = document.getElementById('summarizeBtn');
        const translateBtn = document.getElementById('translateBtn');
        const templateSelect = document.getElementById('templateSelect');
        const askGeminiBtn = document.getElementById('askGeminiBtn');
        const geminiAnswerOutput = document.getElementById('geminiAnswerOutput');

        // MediaRecorder variables
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob = null;
        let audioUrl = null; 

        // Function to update button states and messages
        function updateUI(state, message = '') {
            startRecordBtn.disabled = true;
            stopAndTranscribeBtn.disabled = true;
            copyTextBtn.disabled = true;
            saveToNotionBtn.disabled = true;
            summarizeBtn.disabled = true;
            translateBtn.disabled = true;
            askGeminiBtn.disabled = true;

            startRecordBtn.classList.add('opacity-50', 'cursor-not-allowed');
            stopAndTranscribeBtn.classList.add('opacity-50', 'cursor-not-allowed');
            copyTextBtn.classList.add('opacity-50', 'cursor-not-allowed');
            saveToNotionBtn.classList.add('opacity-50', 'cursor-not-allowed');
            summarizeBtn.classList.add('opacity-50', 'cursor-not-allowed');
            translateBtn.classList.add('opacity-50', 'cursor-not-allowed');
            askGeminiBtn.classList.add('opacity-50', 'cursor-not-allowed');

            startRecordBtn.classList.remove('recording-indicator');

            audioPlayer.src = '';
            if (audioUrl) {
                URL.revokeObjectURL(audioUrl);
                audioUrl = null;
            }

            statusMessage.classList.remove('status-fade-in');
            statusMessage.classList.add('status-fade-out');
            setTimeout(() => {
                statusMessage.textContent = message;
                statusMessage.classList.remove('status-fade-out');
                statusMessage.classList.add('status-fade-in');
            }, 300);

            switch (state) {
                case 'ready':
                    startRecordBtn.disabled = false;
                    startRecordBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    statusMessage.textContent = 'Ready to record or type your note.';
                    transcriptOutput.value = '';
                    geminiAnswerOutput.textContent = "Gemini's answer will appear here.";
                    audioBlob = null;
                    audioChunks = [];
                    updateButtonStatesBasedOnContent();
                    break;
                case 'recording':
                    stopAndTranscribeBtn.disabled = false;
                    stopAndTranscribeBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    startRecordBtn.classList.add('recording-indicator');
                    statusMessage.textContent = 'Recording... Say something!';
                    break;
                case 'transcribing':
                    statusMessage.textContent = 'Transcribing audio... Please wait.';
                    transcriptOutput.value = 'Transcribing...';
                    break;
                case 'processing_llm':
                    statusMessage.textContent = `Processing with Gemini... Please wait.`;
                    break;
                case 'transcribed_for_review':
                    startRecordBtn.disabled = false;
                    startRecordBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    updateButtonStatesBasedOnContent();
                    statusMessage.textContent = 'Transcript ready for review. Edit, copy, or save.';
                    break;
                case 'saving_to_notion':
                    statusMessage.textContent = 'Saving text to Notion...';
                    break;
                case 'saved':
                    statusMessage.textContent = 'Successfully saved to Notion!';
                    transcriptOutput.value = '';
                    updateUI('ready');
                    break;
                case 'error':
                    startRecordBtn.disabled = false;
                    startRecordBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                    updateButtonStatesBasedOnContent();
                    break;
            }
        }

        // Helper function to update button states based on text content
        function updateButtonStatesBasedOnContent() {
            const hasTranscriptContent = transcriptOutput.value.trim() !== '';

            copyTextBtn.disabled = !hasTranscriptContent;
            saveToNotionBtn.disabled = !hasTranscriptContent;
            summarizeBtn.disabled = !hasTranscriptContent;
            translateBtn.disabled = !hasTranscriptContent;

            if (hasTranscriptContent) {
                copyTextBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                saveToNotionBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                summarizeBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                translateBtn.classList.remove('opacity-50', 'cursor-not-allowed');
            } else {
                copyTextBtn.classList.add('opacity-50', 'cursor-not-allowed');
                saveToNotionBtn.classList.add('opacity-50', 'cursor-not-allowed');
                summarizeBtn.classList.add('opacity-50', 'cursor-not-allowed');
                translateBtn.classList.add('opacity-50', 'cursor-not-allowed');
                templateSelect.value = 'general';
            }

            askGeminiBtn.disabled = !hasTranscriptContent;
            if (hasTranscriptContent) {
                askGeminiBtn.classList.remove('opacity-50', 'cursor-not-allowed');
            } else {
                askGeminiBtn.classList.add('opacity-50', 'cursor-not-allowed');
            }
        }

        // --- NEW: Function to handle audio upload to GCS ---
        async function uploadAudioToGCS(audioBlob) {
            try {
                // 1. Get a signed URL from your Vercel API
                const fileName = `voice-notes/${Date.now()}-${Math.random().toString(36).substring(2, 9)}.webm`; // Unique filename
                
                const signedUrlResponse = await fetch('/api/get-signed-url', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ fileName: fileName, contentType: audioBlob.type }),
                });
                const signedUrlData = await signedUrlResponse.json();

                if (!signedUrlResponse.ok) {
                    throw new Error(signedUrlData.error || 'Failed to get signed URL for GCS upload.');
                }
                const { signedUrl, gcsUri } = signedUrlData;

                console.log('Received signed URL for GCS upload:', signedUrl);
                console.log('Target GCS URI:', gcsUri);

                // 2. Upload the audio Blob directly to the signed URL
                const uploadResponse = await fetch(signedUrl, {
                    method: 'PUT',
                    headers: {
                        'Content-Type': audioBlob.type,
                    },
                    body: audioBlob,
                });

                if (!uploadResponse.ok) {
                    const errorText = await uploadResponse.text();
                    console.error('GCS direct upload failed:', errorText);
                    throw new Error(`Failed to upload audio to GCS: ${uploadResponse.status} ${uploadResponse.statusText} - ${errorText}`);
                }

                console.log('Audio uploaded successfully to GCS:', gcsUri);
                return gcsUri; // Return the GCS URI
            } catch (error) {
                console.error('Error in GCS upload process:', error);
                throw error; // Re-throw to be caught by calling function
            }
        }


        // Function to handle transcription logic (updated to use GCS)
        async function handleTranscription() {
            if (!audioBlob || audioBlob.size === 0) {
                statusMessage.textContent = 'No audio recorded to transcribe.';
                updateUI('error');
                return;
            }

            updateUI('transcribing');

            try {
                // Upload audio to GCS first
                const gcsUri = await uploadAudioToGCS(audioBlob);

                // Then send the GCS URI to your transcribe-and-save API
                const response = await fetch('/api/transcribe-and-save', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        gcsUri: gcsUri, // Send the GCS URI instead of base64 audio
                        mimeType: audioBlob.type, // Still useful to send mimeType
                    }),
                });

                const data = await response.json();

                if (response.ok) {
                    const transcribedText = data.transcript || 'No transcript returned.';
                    transcriptOutput.value = transcribedText;
                    updateUI('transcribed_for_review');
                } else {
                    throw new Error(data.error || 'Unknown error from API.');
                }
            } catch (error) {
                console.error('Error in transcription process (via GCS):', error);
                transcriptOutput.value = `Error: ${error.message}`;
                updateUI('error');
            }
        }

        // Function to process text with Gemini for summary or translation
        async function processTextWithGemini(action) {
            const textToProcess = transcriptOutput.value.trim();

            if (!textToProcess) {
                statusMessage.textContent = `Please enter or transcribe some text to ${action}.`;
                return;
            }

            updateUI('processing_llm');

            try {
                const response = await fetch('/api/process-transcript', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        text: textToProcess,
                        action: action,
                    }),
                });

                const data = await response.json();

                if (response.ok) {
                    transcriptOutput.value = data.result || `No ${action} returned.`;
                    updateUI('transcribed_for_review');
                    statusMessage.textContent = `${action.charAt(0).toUpperCase() + action.slice(1)} complete!`;
                } else {
                    throw new Error(data.error || 'Unknown error from API.');
                }
            } catch (error) {
                console.error(`Error processing text for ${action}:`, error);
                transcriptOutput.value = `Error performing ${action}: ${error.message}`;
                updateUI('error');
            }
        }

        // Function to apply template to text (now called onchange)
        async function applyTemplate() {
            const textToTransform = transcriptOutput.value.trim();
            const selectedTemplate = templateSelect.value;

            if (!textToTransform) {
                statusMessage.textContent = 'Please enter or transcribe some text to apply a template.';
                templateSelect.value = 'general';
                return;
            }

            if (selectedTemplate === 'general') {
                statusMessage.textContent = 'No specific template applied. Using general format.';
                return;
            }

            updateUI('processing_llm');

            try {
                const response = await fetch('/api/apply-template', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        text: textToTransform,
                        templateType: selectedTemplate,
                    }),
                });

                const data = await response.json();

                if (response.ok) {
                    transcriptOutput.value = data.transformedText || `Failed to apply template.`;
                    updateUI('transcribed_for_review');
                    statusMessage.textContent = `Template "${selectedTemplate}" applied!`;
                } else {
                    throw new Error(data.error || 'Unknown error from API.');
                }
            } catch (error) {
                console.error('Error applying template:', error);
                transcriptOutput.value = `Error applying template: ${error.message}`;
                updateUI('error');
            }
        }

        // Function for Ask Gemini mode
        async function askGemini() {
            const question = ""; 
            const transcriptContext = transcriptOutput.value.trim();

            if (!transcriptContext) {
                statusMessage.textContent = 'Please transcribe some text to ask Gemini about.';
                return;
            }

            updateUI('processing_llm');
            geminiAnswerOutput.textContent = 'Thinking...';

            try {
                const response = await fetch('/api/ask-gemini', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        question: question,
                        transcript: transcriptContext
                    }),
                });

                const data = await response.json();

                if (response.ok) {
                    geminiAnswerOutput.textContent = data.answer || 'No answer returned.';
                    updateUI('transcribed_for_review');
                    statusMessage.textContent = 'Gemini answered!';
                } else {
                    throw new Error(data.error || 'Unknown error from API.');
                }
            } catch (error) {
                console.error('Error asking Gemini:', error);
                geminiAnswerOutput.textContent = `Error: ${error.message}`;
                updateUI('error');
            }
        }

        // Initialize UI on load
        document.addEventListener('DOMContentLoaded', () => {
            updateUI('ready');
            transcriptOutput.addEventListener('input', updateButtonStatesBasedOnContent);
        });

        // Event listener for starting recording
        startRecordBtn.addEventListener('click', async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = () => {
                    audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    if (audioBlob.size === 0) {
                        console.error('Recorded audio Blob is empty!');
                        statusMessage.textContent = 'Recording failed: No audio captured. Try again.';
                        updateUI('error');
                        stream.getTracks().forEach(track => track.stop());
                        return;
                    }

                    audioUrl = URL.createObjectURL(audioBlob);
                    console.log('Audio Blob created:', audioBlob.type, audioBlob.size, 'bytes. URL:', audioUrl);
                    stream.getTracks().forEach(track => track.stop());

                    handleTranscription(); 
                };

                mediaRecorder.start();
                updateUI('recording');

            } catch (err) {
                console.error('Error accessing microphone:', err);
                statusMessage.textContent = 'Error: Could not access microphone. Please allow access.';
                updateUI('error');
            }
        });

        // Event listener for stopping recording (now "Stop & Transcribe")
        stopAndTranscribeBtn.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
        });

        // Event listener for Copy All Text button
        copyTextBtn.addEventListener('click', () => {
            if (transcriptOutput.value.trim() !== '') {
                const originalSelectionStart = transcriptOutput.selectionStart;
                const originalSelectionEnd = transcriptOutput.selectionEnd;

                transcriptOutput.select();
                transcriptOutput.setSelectionRange(0, 99999);

                try {
                    const success = document.execCommand('copy');
                    if (success) {
                        statusMessage.textContent = 'Text copied to clipboard!';
                    } else {
                        statusMessage.textContent = 'Failed to copy text. Please copy manually.';
                        console.error('document.execCommand("copy") returned false.');
                    }
                } catch (err) {
                    console.error('Failed to copy text (exception): ', err);
                    statusMessage.textContent = 'Failed to copy text. Please copy manually.';
                } finally {
                    transcriptOutput.setSelectionRange(originalSelectionStart, originalSelectionEnd);
                    transcriptOutput.focus();
                }
            } else {
                statusMessage.textContent = 'No text to copy.';
            }
        });

        // Event listener for Save to Notion button
        saveToNotionBtn.addEventListener('click', async () => {
            const textToSave = transcriptOutput.value.trim();

            if (!textToSave) {
                statusMessage.textContent = 'Please enter or transcribe some text to save to Notion.';
                return;
            }

            updateUI('saving_to_notion');

            try {
                const response = await fetch('/api/transcribe-and-save', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        transcript: textToSave,
                    }),
                });

                const data = await response.json();

                if (response.ok) {
                    transcriptOutput.value = data.transcript || textToSave; 
                    updateUI('saved');
                } else {
                    throw new Error(data.error || 'Unknown error from API.');
                }
            } catch (error) {
                console.error('Error saving text to Notion:', error);
                transcriptOutput.value = `Error: ${error.message}`;
                updateUI('error');
            }
        });

        // Event listeners for new LLM buttons
        summarizeBtn.addEventListener('click', () => processTextWithGemini('summarize'));
        translateBtn.addEventListener('click', () => processTextWithGemini('translate'));
        askGeminiBtn.addEventListener('click', askGemini);

    </script>
</body>
</html>
